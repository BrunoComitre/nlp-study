{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "</p><h1 style=\"text-align: center;\"><strong>Using Natural Language Processing</strong></h1>\n",
    "<h2 style=\"text-align: center;\"><strong>to create automatic text summarization</strong></h2>\n",
    "<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the libraries:\n",
    "\n",
    "- NLTK: open source library called Natural Language Toolkit.\n",
    "- Beautiful Soap: Web scraping is a technique of extracting data used to collect data from websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do this, simply execute the following code within REPL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will open the graphical interface of NLTK, where you can choose corporas and models to download:\n",
    "\n",
    "For the tutorial it is recommended to download the following packages:\n",
    "- averaged_perceptron_tagger\n",
    "- floresta\n",
    "- mac_morpho\n",
    "- machado\n",
    "- punkt\n",
    "- stopwords\n",
    "- wordnet\n",
    "- words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Site Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read a News:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = Request('https://www.nexojornal.com.br/externo/2019/01/12/5-revela%C3%A7%C3%B5es-da-psicologia-para-voc%C3%AA-encontrar-sua-verdadeira-voca%C3%A7%C3%A3o',headers={'User-Agent': 'Mozilla/5.0'})\n",
    "page = urlopen(link).read().decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information returned will be stored in a variable named page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To pan the Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Page:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step it is important to know that the code depends on the structure of the page that we are collecting, that is, we must modify it to pan other pages.\n",
    "\n",
    "On the Nexo Journal website the [news](https://www.nexojornal.com.br/externo/2019/01/12/5-revela%C3%A7%C3%B5es-da-psicologia-para-voc%C3%AA-encontrar-sua-verdadeira-voca%C3%A7%C3%A3o) is inside a DIV with ID = content-body-548-15316."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(pagina, \"lxml\")\n",
    "text = soup.find(id=\"content-body-548-153162\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we're going to do is perform a search for the elements that have ID = content-body-548-15316. To make a filter and just catch the news on the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Toolkit (NLTK) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Divide the text into sentences and then into words:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sent_tokenize(text)\n",
    "words = word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing stopwords from the word list:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('portuguese') + list(punctuation))\n",
    "words_without_stopwords = [word for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK tokenizer process considers the text scores as tokens as well and so we can not miss them too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using SET (does not allow repeated elements) and also list comprehension.\n",
    "\n",
    "Setting the language of the stopwords we want, Portuguese.\n",
    "\n",
    "We also remove all scores using ponctuation from the string library.\n",
    "\n",
    "Now we have our list of text words without the stopwords, stored in the variable words_without_stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Distribution and Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discovering Frequency:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = FreqDist(words_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Important Sentences:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "byword_importants = defaultdict(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score was created for each sentence based on the number of times an important word is repeated within it.\n",
    "\n",
    "A special dictionary called defaultdict from the collections library was used.\n",
    "\n",
    "The main difference for a common dictionary is that it does not throw an exception when you search for a non-existent key (KeyError). Instead, it adds this key in the dictionary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polulating Dictionary.:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a looping to go through all the sentences and collect all the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentences in enumerate(sentence):\n",
    "    for word in word_tokenize(sentences.lower()):\n",
    "        if word in frequency:\n",
    "            byword_importants[i] += frequency[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above code populates the dictionary with the index of the sentence (key) and the sum of the frequency of each word present in the sentence (value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate, the nlargest functionality of the heapq library was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting in the dictionary the \"n\" most important sentences to form our summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_byword_importants = nlargest(4, byword_importants, byword_importants.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, you have chosen the 4 most important sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's our news summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O que você precisa fazer é primeiro descobrir sua paixão — aquilo que realmente é importante para você.”Barack ObamaSe você, como muitos, está procurando por seu chamado na vida – talvez você ainda esteja incerto sobre qual profissão se alinha com o que é mais importante – aqui estão cinco descobertas de pesquisas recentes que merecem ser levadas em consideração.Primeiro, há uma diferença entre ter uma paixão harmoniosa e uma paixão obsessiva.\n",
      "Eles concluíram: “ter um chamado é apenas um benefício se for realizado, mas pode ser um prejuízo quando não for, mesmo em comparação a não ter nenhum chamado\".A terceira descoberta a ter em mente é que, sem paixão, a ousadia é “apenas uma dia-a-dia atarefado”.\n",
      "Duckworth sempre enfatizou que existe aí outro componente vital que nos traz de volta à paixão – ao lado da persistência, ela diz que as pessoas corajosas também têm um “interesse maior” (outra maneira de descrever a existência de uma paixão ou de um chamado).Se você continua sem chegar a lugar algum, talvez valha a pena dar atenção ao conselho de outros que dizem que nem sempre a energia e a determinação fluem da descoberta da sua paixãoNo entanto, de acordo com um artigo publicado no ano passado, a medida padrão da ousadia não conseguiu avaliar a paixão (ou mais especificamente, a realização de paixão”) – e Jon Jachimowicz da Columbia Business School, em Nova York, e colegas acreditam que isso poderia explicar por que a pesquisa sobre a ousadia tem sido tão inconsistente (levando a alegações de que é um conceito exagerado e nada mais que a conscienciosidade reembalada).\n",
      "Em um artigo disponibilizado no PsyArXiv, antes da publicação acadêmica, Jachimowicz e sua equipe fazem uma distinção entre pessoas que acreditam que a paixão vem de fazer o que você gosta (que eles dizem estar contido no discurso de formatura que Oprah Winfrey fez em 2008 em que disse que as paixões “florescem quando estamos fazendo o que amamos”), e aqueles que vêem isso como vindo de fazer algo em que você acredita ou valoriza na vida (como refletido nas palavras do ex-presidente mexicano Felipe Calderón que, em um discurso de formatura de 2011, disse “você tem que abraçar com paixão as coisas em que acredita e pelas quais está lutando”).Os pesquisadores descobriram que as pessoas que acreditam que a paixão vem do trabalho prazeroso estavam menos propensas a sentir que haviam encontrado sua paixão (e mais propensas a querer deixar o emprego) quando comparadas a pessoas que acreditam que a paixão vem de fazer algo que você sente que importa.\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(idx_byword_importants):\n",
    "    print(sentence[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p>&nbsp;</p>\n",
    "<h1 style=\"text-align: center;\"><strong><span lang=\"pt\">CONCLUSION</strong></span></h1>\n",
    "<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial made by the author: Vinícius R. Lima, and can be found [here](https://medium.com/@viniljf/utilizando-processamento-de-linguagem-natural-para-criar-um-sumariza%C3%A7%C3%A3o-autom%C3%A1tica-de-textos-775cb428c84e).\n",
    "\n",
    "As a challenge, modify to extract texts from other sites, from txt files, among others.\n",
    "\n",
    "I'm using this as a basis for acquiring NLP (Natural Language Processing) and Web Scraping skills, since with this template it's so easy to perform automatic text summarization using Python libraries on web sites, or from any source for later create a summary of the text.\n",
    "\n",
    "**References:**\n",
    "- [NLTK - Natural Language Toolkit: documentation](http://www.nltk.org/)\n",
    "- [Beautiful Soup: Python library for pulling data out of HTML and XML files.](https://www.crummy.com/software/BeautifulSoup/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INSTALLED VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.6.6.final.0\n",
      "python-bits: 64\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: None\n",
      "LOCALE: None.None\n",
      "\n",
      "pandas: 0.23.4\n",
      "pytest: 3.9.1\n",
      "pip: 18.1\n",
      "setuptools: 40.4.3\n",
      "Cython: 0.29.1\n",
      "numpy: 1.15.4\n",
      "scipy: 1.1.0\n",
      "pyarrow: None\n",
      "xarray: None\n",
      "IPython: 7.0.1\n",
      "sphinx: 1.8.1\n",
      "patsy: 0.5.0\n",
      "dateutil: 2.7.5\n",
      "pytz: 2018.5\n",
      "blosc: None\n",
      "bottleneck: 1.2.1\n",
      "tables: 3.4.4\n",
      "numexpr: 2.6.8\n",
      "feather: None\n",
      "matplotlib: 2.2.2\n",
      "openpyxl: 2.5.9\n",
      "xlrd: 1.1.0\n",
      "xlwt: 1.3.0\n",
      "xlsxwriter: 1.1.2\n",
      "lxml: 4.1.1\n",
      "bs4: 4.6.3\n",
      "html5lib: 1.0.1\n",
      "sqlalchemy: 1.2.14\n",
      "pymysql: None\n",
      "psycopg2: None\n",
      "jinja2: 2.10\n",
      "s3fs: None\n",
      "fastparquet: None\n",
      "pandas_gbq: None\n",
      "pandas_datareader: None\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
